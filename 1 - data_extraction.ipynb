{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILMCLUB_FOLDER = r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\film_club_data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\tmdb_auth.env\")\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = '''\n",
    "tmdb_url = \"https://api.themoviedb.org/3/account/21623434/rated/movies?language=en-US&page=1&sort_by=created_at.asc\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {access_token}\"\n",
    "}\n",
    "'''\n",
    "\n",
    "#response = requests.get(tmdb_url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = json.loads(response.text)\n",
    "#data['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Letterboxd Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract raw HTML data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads through a Letterboxd list and gets the url for each movie in it\n",
    "\n",
    "def get_film_urls_lbxdlist(list_url):\n",
    "    content = requests.get(list_url).text\n",
    "    soup = BeautifulSoup(content, 'html')\n",
    "\n",
    "    url_list = [div['data-target-link'] for div in soup.find_all('div', class_='film-poster')]\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through all the pages of films watched in a user's account and gets the urls of each one\n",
    "\n",
    "def get_film_urls_lbxduser(username):\n",
    "    pages = int(\n",
    "        BeautifulSoup(\n",
    "            requests.get(f'https://letterboxd.com/{username}/films/').text, 'html.parser')\n",
    "            .find_all('li', 'paginate-page')[-1].get_text()\n",
    "        )\n",
    "\n",
    "    url_list = []\n",
    "    for page in range(1, (pages+1)):\n",
    "        print(f\"Extracting page {page} out of {pages}.\")\n",
    "        url = f'https://letterboxd.com/{username}/films/page/{page}/'\n",
    "        content = requests.get(url).text\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        page_url_list = [div['data-target-link'] for div in soup.find_all('div', 'film-poster')]\n",
    "        url_list += page_url_list\n",
    "    \n",
    "    print(\"Finished.\")\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the complete, raw HTML fom a URL\n",
    "\n",
    "def get_raw_film_html(film_url):\n",
    "    url = \"https://letterboxd.com\" + film_url\n",
    "    content = requests.get(url).text\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures general data and metadata about the film \n",
    "\n",
    "def get_general_film_data(soup):\n",
    "    duration_string = soup.find(class_='text-footer').get_text().replace('\\xa0', ' ').strip()\n",
    "\n",
    "    general_data = {\n",
    "        'letterboxd_id': soup.find(id='backdrop')['data-film-id'],\n",
    "        'letterboxd_shorttitle': soup.find('h1', class_='filmtitle').get_text(),\n",
    "        'letterboxd_longtitle': soup.find(property='og:title')['content'],\n",
    "        'letterboxd_slug': soup.find(id='backdrop')['data-film-slug'],\n",
    "        'letterboxd_url': soup.find(property='og:url')['content'],\n",
    "        'imdb_url': '',\n",
    "        'tmdb_url': soup.find('a', {'data-track-action': 'TMDb'})['href'],\n",
    "        'tmdb_id': '',\n",
    "        'release_year': soup.find(class_='releaseyear').find('a').get_text(strip=True),\n",
    "        'duration': '',\n",
    "        'avg_rating': ''\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        general_data['duration'] = re.search(r'(\\d+)\\s+mins', duration_string).group(1)\n",
    "    except:\n",
    "        general_data['duration'] = ''\n",
    "    \n",
    "    try:\n",
    "        general_data['avg_rating'] = soup.find('meta', attrs={'name': 'twitter:data2'})['content'].split(' out')[0]\n",
    "    except:\n",
    "        general_data['avg_rating'] = ''\n",
    "\n",
    "    try:\n",
    "        general_data['imdb_url'] = soup.find('a', {'data-track-action': 'IMDb'})['href']\n",
    "    except:\n",
    "        general_data['imdb_url'] = ''\n",
    "\n",
    "    general_data['tmdb_id'] = general_data['tmdb_url'].split('/')[-2]\n",
    "\n",
    "    return general_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's cast\n",
    "\n",
    "def get_film_cast(soup):\n",
    "    cast_list = []\n",
    "\n",
    "    try:\n",
    "        cast = soup.find(name='div', class_='cast-list').find_all('a', class_='tooltip')\n",
    "\n",
    "        for member in cast:\n",
    "            cast_member_info = {\n",
    "                'name': member.get_text(strip=True),\n",
    "                'link': member['href']\n",
    "                #'character_name': member['title']\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                cast_member_info['character_name'] = member['title']\n",
    "            except:\n",
    "                cast_member_info['character_name'] = None\n",
    "            cast_list.append(cast_member_info)\n",
    "    except:\n",
    "        cast_list = []\n",
    "\n",
    "    return cast_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's crew\n",
    "\n",
    "def get_film_crew(soup):\n",
    "    crew_list = []\n",
    "\n",
    "    try:\n",
    "        crew = soup.find(id='tab-crew').find_all('a')\n",
    "\n",
    "        for member in crew:\n",
    "            split_link = member['href'].split('/')\n",
    "            \n",
    "            crew_member_info = {\n",
    "                'name': member.get_text(strip=True),\n",
    "                'role': split_link[1],\n",
    "                'link': member['href'],\n",
    "            }\n",
    "            crew_list.append(crew_member_info)\n",
    "    except:\n",
    "        crew_list = []\n",
    "    \n",
    "    return crew_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about other details concerning the movie\n",
    "\n",
    "def get_film_details(soup):\n",
    "    details_list = []\n",
    "    details = soup.find(id='tab-details').find_all('a')\n",
    "\n",
    "    for detail in details:\n",
    "        split_link = detail['href'].split('/')\n",
    "\n",
    "        detail_info = {\n",
    "            'key': '',\n",
    "            'value': detail.get_text(strip=True),\n",
    "            'link': detail['href']\n",
    "        }\n",
    "\n",
    "        if 'studio' in detail['href']:\n",
    "            detail_info['key'] = 'studio'\n",
    "        elif 'country' in detail['href']:\n",
    "            detail_info['key'] = 'country'\n",
    "        elif 'language' in detail['href']:\n",
    "            detail_info['key'] = 'language'\n",
    "        else:\n",
    "            detail_info['key'] = 'ERROR'\n",
    "        details_list.append(detail_info)\n",
    "\n",
    "    return details_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's genres and themes\n",
    "\n",
    "def get_film_genres(soup):\n",
    "    genres = [a_tag.get_text(strip=True) for a_tag in soup.find(id='tab-genres').find_all('a')]\n",
    "\n",
    "    return genres[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a loop using the previous functions to extract all the relevant data and unify it in a dict\n",
    "\n",
    "def get_complete_film_data(film_url):\n",
    "    film_soup = get_raw_film_html(film_url)\n",
    "\n",
    "    film_data = {\n",
    "        'general_data': get_general_film_data(film_soup),\n",
    "        'cast': get_film_cast(film_soup),\n",
    "        'crew': get_film_crew(film_soup),\n",
    "        'details': get_film_details(film_soup),\n",
    "        'genres_and_themes': get_film_genres(film_soup)\n",
    "    }\n",
    "\n",
    "    return film_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through all URLs in a list, extracting and structuring data from all of them\n",
    "\n",
    "def get_all_films(url_list):\n",
    "    whole_data = []\n",
    "\n",
    "    counter = 0\n",
    "    for film in url_list:\n",
    "        print(f\"Extracting from URL #{counter}:\\n{film}\\n\")\n",
    "        whole_data.append(get_complete_film_data(film))\n",
    "        counter += 1\n",
    "    \n",
    "    return whole_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms the data dictionaries into dataframes\n",
    "\n",
    "def dicts_to_dfs(data):\n",
    "    all_dfs_gdata = [] # general data\n",
    "    all_dfs_cast = []\n",
    "    all_dfs_crew = []\n",
    "    all_dfs_details = []\n",
    "    all_dfs_gthemes = []\n",
    "\n",
    "\n",
    "    for film in data:\n",
    "        id = film['general_data']['letterboxd_id']\n",
    "        title = film['general_data']['letterboxd_shorttitle']\n",
    "        \n",
    "        single_df_gdata = pd.DataFrame.from_dict([film['general_data']])\n",
    "        all_dfs_gdata.append(single_df_gdata)\n",
    "\n",
    "        single_df_cast = pd.DataFrame.from_dict(film['cast']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_cast.append(single_df_cast)\n",
    "\n",
    "        single_df_crew = pd.DataFrame.from_dict(film['crew']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_crew.append(single_df_crew)\n",
    "\n",
    "        single_df_details = pd.DataFrame.from_dict(film['details']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_details.append(single_df_details)\n",
    "\n",
    "        single_df_gthemes = pd.DataFrame.from_dict(film['genres_and_themes']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_gthemes.append(single_df_gthemes)\n",
    "\n",
    "    all_dfs_dict = {\n",
    "        'df_gdata': pd.concat(all_dfs_gdata),\n",
    "        'df_cast': pd.concat(all_dfs_cast),\n",
    "        'df_crew': pd.concat(all_dfs_crew),\n",
    "        'df_details': pd.concat(all_dfs_details),\n",
    "        'df_gthemes': pd.concat(all_dfs_gthemes)\n",
    "    }\n",
    "\n",
    "    return all_dfs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, create and treat DFs - Film Club Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filmclub_film_urls = get_film_urls_lbxdlist(\"https://letterboxd.com/dromemario/list/fff-film-fueled-friends/\")\n",
    "\n",
    "#filmclub_films_data = get_all_films(film_urls)\n",
    "\n",
    "#all_dfs_dict = dicts_to_dfs(films_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfornow = '''\n",
    "df_generaldata = (\n",
    "    all_dfs_dict['df_gdata'][[\n",
    "        'letterboxd_id',\n",
    "        'letterboxd_shorttitle',\n",
    "        'letterboxd_longtitle',\n",
    "        'letterboxd_slug',\n",
    "        'tmdb_id',\n",
    "        'release_year',\n",
    "        'duration',\n",
    "        'avg_rating',\n",
    "        'letterboxd_url',\n",
    "        'tmdb_url',\n",
    "        'imdb_url'\n",
    "        ]]\n",
    "    .astype({\n",
    "        'release_year': 'int64',\n",
    "        'duration': 'int64',\n",
    "        'avg_rating': 'float64',\n",
    "        'letterboxd_url': 'string',\n",
    "        'tmdb_url': 'string',\n",
    "        'imdb_url': 'string'\n",
    "        })\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cast = (\n",
    "    all_dfs_dict['df_cast'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'link',\n",
    "        'character_name'\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_cast']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_crew = (\n",
    "    all_dfs_dict['df_crew'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'role',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_crew']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_details = (\n",
    "    all_dfs_dict['df_details'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'key',\n",
    "        'value',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_details']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_genresthemes = (\n",
    "    all_dfs_dict['df_gthemes'].rename(columns={0: 'value'})[[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'value'\n",
    "    ]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfornowagain = '''\n",
    "df_generaldata.to_csv(f'{FILMCLUB_FOLDER}fc_generaldata.csv', sep=';', index=False)\n",
    "df_cast.to_csv(f'{FILMCLUB_FOLDER}fc_cast.csv', sep=';', index=False)\n",
    "df_crew.to_csv(f'{FILMCLUB_FOLDER}fc_crew.csv', sep=';', index=False)\n",
    "df_details.to_csv(f'{FILMCLUB_FOLDER}fc_details.csv', sep=';', index=False)\n",
    "df_genresthemes.to_csv(f'{FILMCLUB_FOLDER}fc_genresthemes.csv', sep=';', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, create and treat DFs - Single User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1 out of 15.\n",
      "Extracting page 2 out of 15.\n",
      "Extracting page 3 out of 15.\n",
      "Extracting page 4 out of 15.\n",
      "Extracting page 5 out of 15.\n",
      "Extracting page 6 out of 15.\n",
      "Extracting page 7 out of 15.\n",
      "Extracting page 8 out of 15.\n",
      "Extracting page 9 out of 15.\n",
      "Extracting page 10 out of 15.\n",
      "Extracting page 11 out of 15.\n",
      "Extracting page 12 out of 15.\n",
      "Extracting page 13 out of 15.\n",
      "Extracting page 14 out of 15.\n",
      "Extracting page 15 out of 15.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "user_film_urls = get_film_urls_lbxduser('dromemario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from URL #0:\n",
      "/film/repulsion/\n",
      "\n",
      "Extracting from URL #1:\n",
      "/film/the-umbrellas-of-cherbourg/\n",
      "\n",
      "Extracting from URL #2:\n",
      "/film/dr-strangelove-or-how-i-learned-to-stop-worrying-and-love-the-bomb/\n",
      "\n",
      "Extracting from URL #3:\n",
      "/film/from-russia-with-love/\n",
      "\n",
      "Extracting from URL #4:\n",
      "/film/barren-lives/\n",
      "\n",
      "Extracting from URL #5:\n",
      "/film/8-half/\n",
      "\n",
      "Extracting from URL #6:\n",
      "/film/harakiri/\n",
      "\n",
      "Extracting from URL #7:\n",
      "/film/antoine-and-colette/\n",
      "\n",
      "Extracting from URL #8:\n",
      "/film/cleo-from-5-to-7/\n",
      "\n",
      "Extracting from URL #9:\n",
      "/film/la-jetee/\n",
      "\n",
      "Extracting from URL #10:\n",
      "/film/through-a-glass-darkly/\n",
      "\n",
      "Extracting from URL #11:\n",
      "/film/psycho/\n",
      "\n",
      "Extracting from URL #12:\n",
      "/film/pickpocket/\n",
      "\n",
      "Extracting from URL #13:\n",
      "/film/hiroshima-mon-amour/\n",
      "\n",
      "Extracting from URL #14:\n",
      "/film/the-400-blows/\n",
      "\n",
      "Extracting from URL #15:\n",
      "/film/vertigo/\n",
      "\n",
      "Extracting from URL #16:\n",
      "/film/witness-for-the-prosecution-1957/\n",
      "\n",
      "Extracting from URL #17:\n",
      "/film/12-angry-men/\n",
      "\n",
      "Extracting from URL #18:\n",
      "/film/the-seventh-seal/\n",
      "\n",
      "Extracting from URL #19:\n",
      "/film/forbidden-planet/\n",
      "\n",
      "Extracting from URL #20:\n",
      "/film/rebel-without-a-cause/\n",
      "\n",
      "Extracting from URL #21:\n",
      "/film/rear-window/\n",
      "\n",
      "Extracting from URL #22:\n",
      "/film/dial-m-for-murder/\n",
      "\n",
      "Extracting from URL #23:\n",
      "/film/high-noon/\n",
      "\n",
      "Extracting from URL #24:\n",
      "/film/alice-in-wonderland-1951/\n",
      "\n",
      "Extracting from URL #25:\n",
      "/film/rashomon/\n",
      "\n",
      "Extracting from URL #26:\n",
      "/film/gaslight-1944/\n",
      "\n",
      "Extracting from URL #27:\n",
      "/film/meshes-of-the-afternoon/\n",
      "\n",
      "Extracting from URL #28:\n",
      "/film/casablanca/\n",
      "\n",
      "Extracting from URL #29:\n",
      "/film/citizen-kane/\n",
      "\n",
      "Extracting from URL #30:\n",
      "/film/fantasia/\n",
      "\n",
      "Extracting from URL #31:\n",
      "/film/the-wizard-of-oz-1939/\n",
      "\n",
      "Extracting from URL #32:\n",
      "/film/gone-with-the-wind/\n",
      "\n",
      "Extracting from URL #33:\n",
      "/film/modern-times/\n",
      "\n",
      "Extracting from URL #34:\n",
      "/film/lage-dor/\n",
      "\n",
      "Extracting from URL #35:\n",
      "/film/metropolis/\n",
      "\n",
      "Extracting from URL #36:\n",
      "/film/nosferatu/\n",
      "\n",
      "Extracting from URL #37:\n",
      "/film/the-cabinet-of-dr-caligari-1920/\n",
      "\n",
      "Extracting from URL #38:\n",
      "/film/falling-leaves-1912/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wholedata = get_all_films(user_film_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsoup = get_raw_film_html(user_film_urls[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'letterboxd_id': '882450',\n",
       " 'letterboxd_shorttitle': 'Top Gunner: Danger Zone',\n",
       " 'letterboxd_longtitle': 'Top Gunner: Danger Zone (2022)',\n",
       " 'letterboxd_slug': 'top-gunner-danger-zone',\n",
       " 'letterboxd_url': 'https://letterboxd.com/film/top-gunner-danger-zone/',\n",
       " 'imdb_url': 'http://www.imdb.com/title/tt20726444/maindetails',\n",
       " 'tmdb_url': 'https://www.themoviedb.org/movie/980083/',\n",
       " 'tmdb_id': '980083',\n",
       " 'release_year': '2022',\n",
       " 'duration': '86',\n",
       " 'avg_rating': ''}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_general_film_data(testsoup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
