{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, HTML, Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILMCLUB_FOLDER = r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\film_club_data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\tmdb_auth.env\")\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = '''\n",
    "tmdb_url = \"https://api.themoviedb.org/3/account/21623434/rated/movies?language=en-US&page=1&sort_by=created_at.asc\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {access_token}\"\n",
    "}\n",
    "'''\n",
    "\n",
    "#response = requests.get(tmdb_url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = json.loads(response.text)\n",
    "#data['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Letterboxd Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract raw HTML data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads through a Letterboxd list and gets the url for each movie in it\n",
    "\n",
    "def get_film_urls_lbxdlist(list_url):\n",
    "    content = requests.get(list_url).text\n",
    "    soup = BeautifulSoup(content, 'html')\n",
    "\n",
    "    url_list = [div['data-target-link'] for div in soup.find_all('div', class_='film-poster')]\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the complete, raw HTML fom a URL\n",
    "\n",
    "def get_raw_film_html(film_url):\n",
    "    url = \"https://letterboxd.com\" + film_url\n",
    "    content = requests.get(url).text\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures general data and metadata about the film \n",
    "\n",
    "def get_general_film_data(soup):\n",
    "    duration_string = soup.find(class_='text-footer').get_text().replace('\\xa0', ' ').strip()\n",
    "\n",
    "    general_data = {\n",
    "        'letterboxd_id': soup.find(id='backdrop')['data-film-id'],\n",
    "        'letterboxd_shorttitle': soup.find('h1', class_='filmtitle').get_text(),\n",
    "        'letterboxd_longtitle': soup.find(property='og:title')['content'],\n",
    "        'letterboxd_slug': soup.find(id='backdrop')['data-film-slug'],\n",
    "        'letterboxd_url': soup.find(property='og:url')['content'],\n",
    "        'imdb_url': soup.find('a', {'data-track-action': 'IMDb'})['href'],\n",
    "        'tmdb_url': soup.find('a', {'data-track-action': 'TMDb'})['href'],\n",
    "        'tmdb_id': '',\n",
    "        'release_year': soup.find(class_='releaseyear').find('a').get_text(strip=True),\n",
    "        'duration': re.search(r'(\\d+)\\s+mins', duration_string).group(1),\n",
    "        'avg_rating': soup.find('meta', attrs={'name': 'twitter:data2'})['content'].split(' out')[0]\n",
    "    }\n",
    "\n",
    "    general_data['tmdb_id'] = general_data['tmdb_url'].split('/')[-2]\n",
    "\n",
    "    return general_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's cast\n",
    "\n",
    "def get_film_cast(soup):\n",
    "    cast_list = []\n",
    "    cast = soup.find(name='div', class_='cast-list').find_all('a', class_='tooltip')\n",
    "\n",
    "    for member in cast:\n",
    "        cast_member_info = {\n",
    "            'name': member.get_text(strip=True),\n",
    "            'link': member['href']\n",
    "            #'character_name': member['title']\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            cast_member_info['character_name'] = member['title']\n",
    "        except:\n",
    "            cast_member_info['character_name'] = None\n",
    "        cast_list.append(cast_member_info)\n",
    "\n",
    "    return cast_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's crew\n",
    "\n",
    "def get_film_crew(soup):\n",
    "    crew_list = []\n",
    "    crew = soup.find(id='tab-crew').find_all('a')\n",
    "\n",
    "    for member in crew:\n",
    "        split_link = member['href'].split('/')\n",
    "        \n",
    "        crew_member_info = {\n",
    "            'name': member.get_text(strip=True),\n",
    "            'role': split_link[1],\n",
    "            'link': member['href'],\n",
    "        }\n",
    "        crew_list.append(crew_member_info)\n",
    "    \n",
    "    return crew_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about other details concerning the movie\n",
    "\n",
    "def get_film_details(soup):\n",
    "    details_list = []\n",
    "    details = soup.find(id='tab-details').find_all('a')\n",
    "\n",
    "    for detail in details:\n",
    "        split_link = detail['href'].split('/')\n",
    "\n",
    "        detail_info = {\n",
    "            'key': '',\n",
    "            'value': detail.get_text(strip=True),\n",
    "            'link': detail['href']\n",
    "        }\n",
    "\n",
    "        if 'studio' in detail['href']:\n",
    "            detail_info['key'] = 'studio'\n",
    "        elif 'country' in detail['href']:\n",
    "            detail_info['key'] = 'country'\n",
    "        elif 'language' in detail['href']:\n",
    "            detail_info['key'] = 'language'\n",
    "        else:\n",
    "            detail_info['key'] = 'ERROR'\n",
    "        details_list.append(detail_info)\n",
    "\n",
    "    return details_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's genres and themes\n",
    "\n",
    "def get_film_genres(soup):\n",
    "    genres = [a_tag.get_text(strip=True) for a_tag in soup.find(id='tab-genres').find_all('a')]\n",
    "\n",
    "    return genres[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a loop using the previous functions to extract all the relevant data and unify it in a dict\n",
    "\n",
    "def get_complete_film_data(film_url):\n",
    "    film_soup = get_raw_film_html(film_url)\n",
    "\n",
    "    film_data = {\n",
    "        'general_data': get_general_film_data(film_soup),\n",
    "        'cast': get_film_cast(film_soup),\n",
    "        'crew': get_film_crew(film_soup),\n",
    "        'details': get_film_details(film_soup),\n",
    "        'genres_and_themes': get_film_genres(film_soup)\n",
    "    }\n",
    "\n",
    "    return film_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through all URLs in a list, extracting and structuring data from all of them\n",
    "\n",
    "def get_all_films(url_list):\n",
    "    whole_data = []\n",
    "\n",
    "    counter = 0\n",
    "    for film in url_list:\n",
    "        #print(f\"Extracting from URL #{counter}:\\n{film}\\n\")\n",
    "        whole_data.append(get_complete_film_data(film))\n",
    "        counter += 1\n",
    "    \n",
    "    return whole_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms the data dictionaries into dataframes\n",
    "\n",
    "def dicts_to_dfs(data):\n",
    "    all_dfs_gdata = [] # general data\n",
    "    all_dfs_cast = []\n",
    "    all_dfs_crew = []\n",
    "    all_dfs_details = []\n",
    "    all_dfs_gthemes = []\n",
    "\n",
    "\n",
    "    for film in data:\n",
    "        id = film['general_data']['letterboxd_id']\n",
    "        title = film['general_data']['letterboxd_shorttitle']\n",
    "        \n",
    "        single_df_gdata = pd.DataFrame.from_dict([film['general_data']])\n",
    "        all_dfs_gdata.append(single_df_gdata)\n",
    "\n",
    "        single_df_cast = pd.DataFrame.from_dict(film['cast']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_cast.append(single_df_cast)\n",
    "\n",
    "        single_df_crew = pd.DataFrame.from_dict(film['crew']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_crew.append(single_df_crew)\n",
    "\n",
    "        single_df_details = pd.DataFrame.from_dict(film['details']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_details.append(single_df_details)\n",
    "\n",
    "        single_df_gthemes = pd.DataFrame.from_dict(film['genres_and_themes']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_gthemes.append(single_df_gthemes)\n",
    "\n",
    "    all_dfs_dict = {\n",
    "        'df_gdata': pd.concat(all_dfs_gdata),\n",
    "        'df_cast': pd.concat(all_dfs_cast),\n",
    "        'df_crew': pd.concat(all_dfs_crew),\n",
    "        'df_details': pd.concat(all_dfs_details),\n",
    "        'df_gthemes': pd.concat(all_dfs_gthemes)\n",
    "    }\n",
    "\n",
    "    return all_dfs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, create and treat DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#film_urls = get_film_urls_lbxdlist(\"https://letterboxd.com/dromemario/list/fff-film-fueled-friends/\")\n",
    "\n",
    "#films_data = get_all_films(film_urls)\n",
    "\n",
    "#with open(\"films_data.json\", \"w\") as json_file:\n",
    "#    json.dump(films_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"films_data.json\", \"r\") as json_file:\n",
    "    films_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs_dict = dicts_to_dfs(films_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generaldata = (\n",
    "    all_dfs_dict['df_gdata'][[\n",
    "        'letterboxd_id',\n",
    "        'letterboxd_shorttitle',\n",
    "        'letterboxd_longtitle',\n",
    "        'letterboxd_slug',\n",
    "        'tmdb_id',\n",
    "        'release_year',\n",
    "        'duration',\n",
    "        'avg_rating',\n",
    "        'letterboxd_url',\n",
    "        'tmdb_url',\n",
    "        'imdb_url'\n",
    "        ]]\n",
    "    .astype({\n",
    "        'release_year': 'int64',\n",
    "        'duration': 'int64',\n",
    "        'avg_rating': 'float64',\n",
    "        'letterboxd_url': 'string',\n",
    "        'tmdb_url': 'string',\n",
    "        'imdb_url': 'string'\n",
    "        })\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cast = (\n",
    "    all_dfs_dict['df_cast'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'link',\n",
    "        'character_name'\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_cast']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_crew = (\n",
    "    all_dfs_dict['df_crew'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'role',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_crew']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_details = (\n",
    "    all_dfs_dict['df_details'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'key',\n",
    "        'value',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_details']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_genresthemes = (\n",
    "    all_dfs_dict['df_gthemes'].rename(columns={0: 'value'})[[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'value'\n",
    "    ]]\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generaldata.to_csv(f'{FILMCLUB_FOLDER}fc_generaldata.csv', sep=';', index=False)\n",
    "df_cast.to_csv(f'{FILMCLUB_FOLDER}fc_cast.csv', sep=';', index=False)\n",
    "df_crew.to_csv(f'{FILMCLUB_FOLDER}fc_crew.csv', sep=';', index=False)\n",
    "df_details.to_csv(f'{FILMCLUB_FOLDER}fc_details.csv', sep=';', index=False)\n",
    "df_genresthemes.to_csv(f'{FILMCLUB_FOLDER}fc_genresthemes.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
